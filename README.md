# RadFuse: Multimodal Transformer for Chest X-ray Diagnosis and Retrieval

## ğŸ§  Introduction
RadFuse is a unified multimodal transformer-based framework designed to jointly model chest radiographs and their associated free-text radiology reports. By combining a Vision Transformer (ViT) for image encoding and ClinicalBERT for text encoding, RadFuse performs:

- Multi-label disease classification
- Image-report retrieval

This repository provides code for training, evaluation, and inference using the RadFuse model, along with visualization utilities for attention heatmaps.

---

## âš™ï¸ Installation

### 1. Clone the repository:
```bash
git clone https://github.com/YourUsername/RadFuse.git
cd RadFuse
```

### 2. Create virtual environment and install dependencies:
```bash
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows
pip install -r requirements.txt
```

### 3. Download datasets:
- **MIMIC-CXR**: [https://physionet.org/content/mimic-cxr/2.0.0/](https://physionet.org/content/mimic-cxr/2.0.0/)
- **IU X-Ray**: [https://openi.nlm.nih.gov/](https://openi.nlm.nih.gov/)

Preprocess the datasets using provided scripts in `data_preprocessing/`.

---

## ğŸš€ Usage

### Example: Run Inference on an X-ray Image
```bash
python run_inference.py --image_path ./examples/sample_xray.png --report_path ./examples/sample_report.txt
```

### Output:
- Predicted disease labels with confidence scores
- Matched report (retrieval mode)
- Attention heatmap overlay (optional)

---

## ğŸ‹ï¸â€â™€ï¸ Train the Model
```bash
python train.py --config configs/train_radfuse.yaml
```

### Configurable Hyperparameters (via YAML):
- `epochs`: number of training epochs
- `batch_size`: size of mini-batches
- `learning_rate`: optimizer learning rate
- `loss_weights`: weights for classification vs retrieval loss

---

## ğŸ“Š Evaluate the Model
```bash
python evaluate.py --checkpoint ./checkpoints/model_final.pth
```
Metrics:
- AUC, F1-score for classification
- Recall@10, MRR for retrieval

---

## ğŸ“ Folder Structure
```
RadFuse/
â”œâ”€â”€ configs/              # YAML configs for training and eval
â”œâ”€â”€ data_preprocessing/   # Scripts to preprocess MIMIC-CXR/IU-XRay
â”œâ”€â”€ models/               # Model architecture (ViT, ClinicalBERT, Fusion)
â”œâ”€â”€ training/             # Training, loss functions
â”œâ”€â”€ evaluation/           # Evaluation metrics and loops
â”œâ”€â”€ visualizations/       # Attention visualizer tools
â”œâ”€â”€ examples/             # Sample images and reports
â”œâ”€â”€ checkpoints/          # Saved weights
â”œâ”€â”€ run_inference.py      # Inference script
â”œâ”€â”€ train.py              # Training launcher
â”œâ”€â”€ evaluate.py           # Evaluation launcher
â””â”€â”€ requirements.txt      # Python dependencies
```

---

## ğŸ‘¨â€ğŸ’» Authors
- Mojtaba Jahanian (Corresponding Author) â€” Mojtaba160672000@aut.ac.ir
- Abbas Karimi â€” Abbas.karimi@iau.ac.ir
- Nafiseh Osati Eraghi â€” Nafiseh.osati@iau.ac.ir
- Faraneh Zarafshan â€” Fzarafshan@aiau.ac.ir

Affiliations: 
- Department of Computer, Arak Branch, Islamic Azad University, Arak, Iran
- Department of Computer, Ashtian Branch, Islamic Azad University, Arak, Iran

---

## ğŸ“„ License
MIT License

---

## âœ¨ Citation
If you use this code, please cite:
```bibtex
@article{radfuse2025,
  title={Multimodal Transformers for Joint Diagnosis and Retrieval from Chest X-rays and Radiology Reports},
  author={Jahanian, Mojtaba and Karimi, Abbas and Osati Eraghi, Nafiseh and Zarafshan, Faraneh},
  journal={Journal Name},
  year={2025}
}
```

---

## â“ Questions or Contributions
Feel free to open an issue or submit a pull request. Contributions are welcome!
